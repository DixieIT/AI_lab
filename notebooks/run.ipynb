{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20326118",
      "metadata": {
        "id": "20326118"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2422f32f",
      "metadata": {
        "id": "2422f32f"
      },
      "source": [
        "## Install BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b10fd32",
      "metadata": {
        "id": "8b10fd32",
        "outputId": "98ba8944-d754-421f-9c1b-b08d5cae5538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BenchMARL' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!git clone https://github.com/facebookresearch/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6cd7b69b",
      "metadata": {
        "id": "6cd7b69b",
        "outputId": "19cf76e6-9f54-40d8-a9a9-c7600aac4128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BenchMARL\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd /content/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4f32b88e",
      "metadata": {
        "id": "4f32b88e",
        "outputId": "c170e142-331a-465d-af9f-7147fc3c8ac9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Obtaining file:///content/BenchMARL\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchrl~=0.6.0 in /usr/local/lib/python3.10/dist-packages (from benchmarl==1.3.0) (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from benchmarl==1.3.0) (4.66.6)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from benchmarl==1.3.0) (1.3.2)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (3.1.0)\n",
            "Requirement already satisfied: tensordict>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (0.6.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core->benchmarl==1.3.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->benchmarl==1.3.0) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->benchmarl==1.3.0) (6.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict>=0.6.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.10.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.0.2)\n",
            "Building wheels for collected packages: benchmarl\n",
            "  Building editable for benchmarl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benchmarl: filename=benchmarl-1.3.0-0.editable-py3-none-any.whl size=3761 sha256=27ecb076a65b7bddec190707b45f3e93925e5fa6180291939abf41cff26be793\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ypy0etsm/wheels/5b/86/4d/eff20c27275b75bdf6b20e4a81af849509b0068ff4c44be9df\n",
            "Successfully built benchmarl\n",
            "Installing collected packages: benchmarl\n",
            "  Attempting uninstall: benchmarl\n",
            "    Found existing installation: benchmarl 1.3.0\n",
            "    Uninstalling benchmarl-1.3.0:\n",
            "      Successfully uninstalled benchmarl-1.3.0\n",
            "Successfully installed benchmarl-1.3.0\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install -U torch torchvision\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585d3a35",
      "metadata": {
        "id": "585d3a35"
      },
      "source": [
        "## Install VMAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2e551b1",
      "metadata": {
        "id": "d2e551b1",
        "outputId": "9e2ed36e-bd3b-4e36-efd6-f4d1acbe8af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vmas in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from vmas) (2.5.1)\n",
            "Requirement already satisfied: pyglet<=1.5.27 in /usr/local/lib/python3.10/dist-packages (from vmas) (1.5.27)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from vmas) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->vmas) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install vmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33d72783",
      "metadata": {
        "id": "33d72783",
        "outputId": "4475b5be-c2e8-4007-f7fb-887ab362652c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 257 kB in 5s (54.9 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+5build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x79cbbf6d2110>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#@title\n",
        "!apt-get update\n",
        "!apt-get install -y x11-utils\n",
        "!apt-get install -y xvfb\n",
        "!apt-get install -y imagemagick\n",
        "!pip install pyvirtualdisplay\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa7225f",
      "metadata": {
        "id": "caa7225f"
      },
      "source": [
        "# Launch from command line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30075032",
      "metadata": {
        "id": "30075032"
      },
      "source": [
        "To launch an experiment from the command line you can do"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5369898f",
      "metadata": {
        "scrolled": false,
        "id": "5369898f",
        "outputId": "bfad51a3-712a-4bea-abe6-e517665dee25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "Error executing job with overrides: ['algorithm=mappo', 'task=vmas/balance', 'experiment.max_n_iters=2', 'experiment.loggers=[]']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 25, in <module>\n",
            "    from pyglet.gl import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/__init__.py\", line 95, in <module>\n",
            "    from pyglet.gl.gl import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/gl.py\", line 45, in <module>\n",
            "    from pyglet.gl.lib import link_GL as _link_function\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib.py\", line 149, in <module>\n",
            "    from pyglet.gl.lib_glx import link_GL, link_GLU, link_GLX\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib_glx.py\", line 46, in <module>\n",
            "    glu_lib = pyglet.lib.load_library('GLU')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/lib.py\", line 168, in load_library\n",
            "    raise ImportError('Library \"%s\" not found.' % names[0])\n",
            "ImportError: Library \"GLU\" not found.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/BenchMARL/benchmarl/run.py\", line 38, in hydra_experiment\n",
            "    experiment.run()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 571, in run\n",
            "    raise err\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 563, in run\n",
            "    self._collection_loop()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 685, in _collection_loop\n",
            "    self._evaluation_loop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 818, in _evaluation_loop\n",
            "    rollouts = self.test_env.rollout(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2641, in rollout\n",
            "    tensordicts = self._rollout_nonstop(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2814, in _rollout_nonstop\n",
            "    callback(self, tensordict)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 798, in callback\n",
            "    self.task.__class__.render_callback(self, env, td)\n",
            "  File \"/content/BenchMARL/benchmarl/environments/common.py\", line 299, in render_callback\n",
            "    return env.render(mode=\"rgb_array\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 706, in render\n",
            "    self._init_rendering()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 879, in _init_rendering\n",
            "    from vmas.simulator import rendering\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 60, in <module>\n",
            "    raise ImportError(\n",
            "ImportError: Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "mean return = -5.014926910400391:   0% 0/2 [00:37<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py algorithm=mappo task=vmas/balance experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f9338f",
      "metadata": {
        "id": "23f9338f"
      },
      "source": [
        "You can run benchmarks as multi-runs like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "90a135ea",
      "metadata": {
        "scrolled": false,
        "id": "90a135ea",
        "outputId": "4d744b56-9430-4033-ef58-2774c93e4b19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-13 08:48:37,707][HYDRA] Launching 12 jobs locally\n",
            "[2024-11-13 08:48:37,707][HYDRA] \t#0 : algorithm=mappo task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:49:14,106][HYDRA] \t#1 : algorithm=mappo task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:49:50,644][HYDRA] \t#2 : algorithm=mappo task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:50:47,493][HYDRA] \t#3 : algorithm=mappo task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:51:43,109][HYDRA] \t#4 : algorithm=qmix task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:52:15,315][HYDRA] \t#5 : algorithm=qmix task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:52:48,034][HYDRA] \t#6 : algorithm=qmix task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:53:40,047][HYDRA] \t#7 : algorithm=qmix task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:54:36,290][HYDRA] \t#8 : algorithm=masac task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:55:29,643][HYDRA] \t#9 : algorithm=masac task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:56:21,938][HYDRA] \t#10 : algorithm=masac task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-13 08:57:20,686][HYDRA] \t#11 : algorithm=masac task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/BenchMARL/benchmarl/run.py\", line 42, in <module>\n",
            "    hydra_experiment()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\", line 465, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 36 leaked semaphore objects to clean up at shutdown\n",
            "  warnings.warn('resource_tracker: There appear to be %d '\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1 experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b01091a",
      "metadata": {
        "id": "0b01091a"
      },
      "source": [
        "# Launch from a python script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c6dc69",
      "metadata": {
        "id": "67c6dc69"
      },
      "source": [
        "You can also load and launch your experiments from within a script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2c5b5fcd",
      "metadata": {
        "id": "2c5b5fcd",
        "outputId": "a01c5094-4faa-4944-f2ca-9bccf273327c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-010b84cad300>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMappoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVmasTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperimentConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMlpConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/algorithms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlgorithmConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0middpg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIddpg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIddpgConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mippo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIppo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIppoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/algorithms/common.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensordict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDictBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDictModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDictSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m from torchrl.data import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensordict/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LICENSE file in the root directory of this source tree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyStackedTensorDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nestedkey\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNestedKey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensordict/_reductions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyStackedTensorDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_td\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from torch._decomp import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0m_convert_out_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;31m# populate the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1019\u001b[0m )\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m eq = _make_elementwise_binary_prim(\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;34m\"eq\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0mimpl_aten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m_make_elementwise_binary_prim\u001b[0;34m(name, type_promotion, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \"\"\"\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m     return _make_prim(\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{name}(Tensor self, Tensor other) -> Tensor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prim_elementwise_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_promotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_promotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m_make_prim\u001b[0;34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api, register_conj_neg_fallthrough)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0m_prim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0maten_packet\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         overload_tags = [\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maten_packet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moverload\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maten_packet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0maten_packet\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         overload_tags = [\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maten_packet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moverload\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maten_packet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         ]\n\u001b[1;32m    340\u001b[0m         \u001b[0mtags_intersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverload_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qualified_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             overload = (\n\u001b[0;32m-> 1087\u001b[0;31m                 \u001b[0mOpOverload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_dk_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_has_script_object_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mTorchBindOpOverload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_dk_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, overloadpacket, op, op_dk, schema, tags)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOpOverload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOperatorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverloadpacket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_dk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_dk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_dk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas/balance.yaml\"\n",
        "task = VmasTask.BALANCE.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/algorithm/mappo.yaml\"\n",
        "algorithm_config = MappoConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/model/layers/mlp.yaml\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "experiment = Experiment(\n",
        "    task=task,\n",
        "    algorithm_config=algorithm_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        "    seed=0,\n",
        "    config=experiment_config,\n",
        ")\n",
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20864e3",
      "metadata": {
        "id": "a20864e3"
      },
      "source": [
        "You can also run multiple experiments in a Benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec3bd4b",
      "metadata": {
        "id": "6ec3bd4b"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig, MasacConfig, QmixConfig\n",
        "from benchmarl.benchmark import Benchmark\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas\"\n",
        "tasks = [VmasTask.BALANCE.get_from_yaml(), VmasTask.SAMPLING.get_from_yaml()]\n",
        "# Loads from \"benchmarl/conf/algorithm\"\n",
        "algorithm_configs = [\n",
        "    MappoConfig.get_from_yaml(),\n",
        "    QmixConfig.get_from_yaml(),\n",
        "    MasacConfig.get_from_yaml(),\n",
        "]\n",
        "# Loads from \"benchmarl/conf/model/layers\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "benchmark = Benchmark(\n",
        "    algorithm_configs=algorithm_configs,\n",
        "    tasks=tasks,\n",
        "    seeds={0, 1},\n",
        "    experiment_config=experiment_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        ")\n",
        "benchmark.run_sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up WANDB"
      ],
      "metadata": {
        "id": "Ny9nTZKnun0U"
      },
      "id": "Ny9nTZKnun0U"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "3cY6yxzVunQh",
        "outputId": "02f210a9-6026-4c52-89b4-4a6a3ca033d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3cY6yxzVunQh",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "ZvCuWGziuzvt",
        "outputId": "39f49602-aadf-46c3-8b4e-491084aa0278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZvCuWGziuzvt",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Via Marl-eval"
      ],
      "metadata": {
        "id": "dn3Dk7ktwrY7"
      },
      "id": "dn3Dk7ktwrY7"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JatbsAJkvwq-"
      },
      "id": "JatbsAJkvwq-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}