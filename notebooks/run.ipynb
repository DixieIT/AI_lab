{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20326118",
      "metadata": {
        "id": "20326118"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2422f32f",
      "metadata": {
        "id": "2422f32f"
      },
      "source": [
        "## Install BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b10fd32",
      "metadata": {
        "id": "8b10fd32",
        "outputId": "bf3534dc-4bfa-4715-912c-9a32e91162d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BenchMARL' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!git clone https://github.com/facebookresearch/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6cd7b69b",
      "metadata": {
        "id": "6cd7b69b",
        "outputId": "43bd57b9-5bcc-4a18-e093-edd899a86da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BenchMARL\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd /content/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4f32b88e",
      "metadata": {
        "id": "4f32b88e",
        "outputId": "2d2b26ba-6559-4db2-d1b9-847e976ad53b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Obtaining file:///content/BenchMARL\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchrl~=0.6.0 in /usr/local/lib/python3.10/dist-packages (from benchmarl==1.3.0) (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from benchmarl==1.3.0) (4.66.6)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from benchmarl==1.3.0) (1.3.2)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (3.1.0)\n",
            "Requirement already satisfied: tensordict>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl==1.3.0) (0.6.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core->benchmarl==1.3.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->benchmarl==1.3.0) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->benchmarl==1.3.0) (6.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict>=0.6.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.10.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5.0->torchrl~=0.6.0->benchmarl==1.3.0) (3.0.2)\n",
            "Building wheels for collected packages: benchmarl\n",
            "  Building editable for benchmarl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benchmarl: filename=benchmarl-1.3.0-0.editable-py3-none-any.whl size=3755 sha256=483ec14c876e002108d8f48b90c2903982ba4acdfcb43a6b7898221b79401886\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m0lf1u9w/wheels/5b/86/4d/eff20c27275b75bdf6b20e4a81af849509b0068ff4c44be9df\n",
            "Successfully built benchmarl\n",
            "Installing collected packages: benchmarl\n",
            "  Attempting uninstall: benchmarl\n",
            "    Found existing installation: benchmarl 1.3.0\n",
            "    Uninstalling benchmarl-1.3.0:\n",
            "      Successfully uninstalled benchmarl-1.3.0\n",
            "Successfully installed benchmarl-1.3.0\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install -U torch torchvision\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585d3a35",
      "metadata": {
        "id": "585d3a35"
      },
      "source": [
        "## Install VMAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2e551b1",
      "metadata": {
        "id": "d2e551b1",
        "outputId": "cc7735ce-412f-44ea-dfc9-239eb6d8d4e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vmas in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from vmas) (2.5.1+cu121)\n",
            "Requirement already satisfied: pyglet<=1.5.27 in /usr/local/lib/python3.10/dist-packages (from vmas) (1.5.27)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from vmas) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->vmas) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install vmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33d72783",
      "metadata": {
        "id": "33d72783",
        "outputId": "c559271d-53a2-4f1d-ccff-39b59569547a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [Connecting to cloud.r\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [Connected to cloud.r-\r                                                                                                    \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecti\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcon\r                                                                                                    \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.\r                                                                                                    \rHit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+5build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7c5dcfeca860>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#@title\n",
        "!apt-get update\n",
        "!apt-get install -y x11-utils\n",
        "!apt-get install -y xvfb\n",
        "!apt-get install -y imagemagick\n",
        "!pip install pyvirtualdisplay\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa7225f",
      "metadata": {
        "id": "caa7225f"
      },
      "source": [
        "# Launch from command line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30075032",
      "metadata": {
        "id": "30075032"
      },
      "source": [
        "To launch an experiment from the command line you can do"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5369898f",
      "metadata": {
        "scrolled": false,
        "id": "5369898f",
        "outputId": "d53d84b3-31c6-4bee-b507-867bc725a884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "Error executing job with overrides: ['algorithm=mappo', 'task=vmas/balance', 'experiment.max_n_iters=2', 'experiment.loggers=[]']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 25, in <module>\n",
            "    from pyglet.gl import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/__init__.py\", line 95, in <module>\n",
            "    from pyglet.gl.gl import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/gl.py\", line 45, in <module>\n",
            "    from pyglet.gl.lib import link_GL as _link_function\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib.py\", line 149, in <module>\n",
            "    from pyglet.gl.lib_glx import link_GL, link_GLU, link_GLX\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib_glx.py\", line 46, in <module>\n",
            "    glu_lib = pyglet.lib.load_library('GLU')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/lib.py\", line 168, in load_library\n",
            "    raise ImportError('Library \"%s\" not found.' % names[0])\n",
            "ImportError: Library \"GLU\" not found.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/BenchMARL/benchmarl/run.py\", line 38, in hydra_experiment\n",
            "    experiment.run()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 597, in run\n",
            "    raise err\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 589, in run\n",
            "    self._collection_loop()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 711, in _collection_loop\n",
            "    self._evaluation_loop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 844, in _evaluation_loop\n",
            "    rollouts = self.test_env.rollout(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2641, in rollout\n",
            "    tensordicts = self._rollout_nonstop(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2814, in _rollout_nonstop\n",
            "    callback(self, tensordict)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 824, in callback\n",
            "    self.task.__class__.render_callback(self, env, td)\n",
            "  File \"/content/BenchMARL/benchmarl/environments/common.py\", line 300, in render_callback\n",
            "    return env.render(mode=\"rgb_array\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 706, in render\n",
            "    self._init_rendering()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 879, in _init_rendering\n",
            "    from vmas.simulator import rendering\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 60, in <module>\n",
            "    raise ImportError(\n",
            "ImportError: Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "mean return = -5.014926910400391:   0% 0/2 [00:32<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py algorithm=mappo task=vmas/balance experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f9338f",
      "metadata": {
        "id": "23f9338f"
      },
      "source": [
        "You can run benchmarks as multi-runs like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "90a135ea",
      "metadata": {
        "scrolled": false,
        "id": "90a135ea",
        "outputId": "7babac83-e94f-46fc-b777-540c541f079f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-29 03:22:31,973][HYDRA] Launching 12 jobs locally\n",
            "[2024-11-29 03:22:31,973][HYDRA] \t#0 : algorithm=mappo task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:23:04,898][HYDRA] \t#1 : algorithm=mappo task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:23:38,024][HYDRA] \t#2 : algorithm=mappo task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:24:30,294][HYDRA] \t#3 : algorithm=mappo task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:25:22,716][HYDRA] \t#4 : algorithm=qmix task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:25:51,165][HYDRA] \t#5 : algorithm=qmix task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:26:20,605][HYDRA] \t#6 : algorithm=qmix task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:27:12,874][HYDRA] \t#7 : algorithm=qmix task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:28:02,032][HYDRA] \t#8 : algorithm=masac task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:28:48,546][HYDRA] \t#9 : algorithm=masac task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:29:35,096][HYDRA] \t#10 : algorithm=masac task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-29 03:30:44,027][HYDRA] \t#11 : algorithm=masac task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "Error executing job with overrides: ['algorithm=mappo', 'task=vmas/balance', 'seed=0', 'experiment.max_n_iters=2', 'experiment.loggers=[]']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 25, in <module>\n",
            "    from pyglet.gl import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/__init__.py\", line 95, in <module>\n",
            "    from pyglet.gl.gl import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/gl.py\", line 45, in <module>\n",
            "    from pyglet.gl.lib import link_GL as _link_function\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib.py\", line 149, in <module>\n",
            "    from pyglet.gl.lib_glx import link_GL, link_GLU, link_GLX\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib_glx.py\", line 46, in <module>\n",
            "    glu_lib = pyglet.lib.load_library('GLU')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/lib.py\", line 168, in load_library\n",
            "    raise ImportError('Library \"%s\" not found.' % names[0])\n",
            "ImportError: Library \"GLU\" not found.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/BenchMARL/benchmarl/run.py\", line 38, in hydra_experiment\n",
            "    experiment.run()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 597, in run\n",
            "    raise err\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 589, in run\n",
            "    self._collection_loop()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 711, in _collection_loop\n",
            "    self._evaluation_loop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 844, in _evaluation_loop\n",
            "    rollouts = self.test_env.rollout(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2641, in rollout\n",
            "    tensordicts = self._rollout_nonstop(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2814, in _rollout_nonstop\n",
            "    callback(self, tensordict)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 824, in callback\n",
            "    self.task.__class__.render_callback(self, env, td)\n",
            "  File \"/content/BenchMARL/benchmarl/environments/common.py\", line 300, in render_callback\n",
            "    return env.render(mode=\"rgb_array\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 706, in render\n",
            "    self._init_rendering()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 879, in _init_rendering\n",
            "    from vmas.simulator import rendering\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 60, in <module>\n",
            "    raise ImportError(\n",
            "ImportError: Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "mean return = -5.014926910400391:   0% 0/2 [09:17<?, ?it/s]\n",
            "mean return = -5.075616359710693:   0% 0/2 [08:45<?, ?it/s]\n",
            "mean return = 3.1488149166107178:   0% 0/2 [08:08<?, ?it/s]\n",
            "mean return = 3.126894950866699:   0% 0/2 [07:16<?, ?it/s]\n",
            "mean return = -10.58658504486084:   0% 0/2 [06:27<?, ?it/s]\n",
            "mean return = -11.010995864868164:   0% 0/2 [05:59<?, ?it/s]\n",
            "mean return = 4.790381908416748:   0% 0/2 [05:22<?, ?it/s]\n",
            "mean return = 3.8009302616119385:   0% 0/2 [04:33<?, ?it/s]\n",
            "mean return = -5.014926910400391:   0% 0/2 [03:48<?, ?it/s]\n",
            "mean return = -5.075616359710693:   0% 0/2 [03:01<?, ?it/s]\n",
            "mean return = 3.126894950866699:   0% 0/2 [01:02<?, ?it/s]\n",
            "mean return = 3.1488149166107178:   0% 0/2 [02:11<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1 experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b01091a",
      "metadata": {
        "id": "0b01091a"
      },
      "source": [
        "# Launch from a python script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c6dc69",
      "metadata": {
        "id": "67c6dc69"
      },
      "source": [
        "You can also load and launch your experiments from within a script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2c5b5fcd",
      "metadata": {
        "id": "2c5b5fcd",
        "outputId": "797f8818-9c02-4c13-ee5d-cd8e5e47c8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     from pyglet.gl import (\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mGL_BLEND\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/gl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mctypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_link_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mc_ptrdiff_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_glx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib_glx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mgl_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mglu_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GLU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/lib.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, *names, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Library \"%s\" not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Library \"GLU\" not found.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-010b84cad300>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/BenchMARL/benchmarl/experiment/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nExperiment failed and is closing gracefully\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/experiment/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collection_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nExperiment was closed gracefully\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/experiment/experiment.py\u001b[0m in \u001b[0;36m_collection_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             ):\n\u001b[0;32m--> 711\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# End of step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/experiment/experiment.py\u001b[0m in \u001b[0;36m_evaluation_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m                     )\n\u001b[1;32m    843\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m                 rollouts = self.test_env.rollout(\n\u001b[0m\u001b[1;32m    845\u001b[0m                     \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[0m\n\u001b[1;32m   2639\u001b[0m             )\n\u001b[1;32m   2640\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2641\u001b[0;31m             \u001b[0mtensordicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rollout_nonstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2642\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtensordict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_rollout_nonstop\u001b[0;34m(self, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   2812\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2814\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensordicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/experiment/experiment.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(env, td)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                     video_frames.append(\n\u001b[0;32m--> 824\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                     )\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/environments/common.py\u001b[0m in \u001b[0;36mrender_callback\u001b[0;34m(experiment, env, data)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEnvBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorDictBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, env_index, agent_index_focus, visualize_when_rgb, plot_position_function, plot_position_function_precision, plot_position_function_range, plot_position_function_cmap_range, plot_position_function_cmap_alpha, plot_position_function_cmap_name)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"headless\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheadless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_rendering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer_zoom\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\u001b[0m in \u001b[0;36m_init_rendering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_rendering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mvmas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         self.viewer = rendering.Viewer(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;34m\"Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas/balance.yaml\"\n",
        "task = VmasTask.BALANCE.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/algorithm/mappo.yaml\"\n",
        "algorithm_config = MappoConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/model/layers/mlp.yaml\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "experiment = Experiment(\n",
        "    task=task,\n",
        "    algorithm_config=algorithm_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        "    seed=0,\n",
        "    config=experiment_config,\n",
        ")\n",
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20864e3",
      "metadata": {
        "id": "a20864e3"
      },
      "source": [
        "You can also run multiple experiments in a Benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec3bd4b",
      "metadata": {
        "id": "6ec3bd4b"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig, MasacConfig, QmixConfig\n",
        "from benchmarl.benchmark import Benchmark\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas\"\n",
        "tasks = [VmasTask.BALANCE.get_from_yaml(), VmasTask.SAMPLING.get_from_yaml()]\n",
        "# Loads from \"benchmarl/conf/algorithm\"\n",
        "algorithm_configs = [\n",
        "    MappoConfig.get_from_yaml(),\n",
        "    QmixConfig.get_from_yaml(),\n",
        "    MasacConfig.get_from_yaml(),\n",
        "]\n",
        "# Loads from \"benchmarl/conf/model/layers\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "benchmark = Benchmark(\n",
        "    algorithm_configs=algorithm_configs,\n",
        "    tasks=tasks,\n",
        "    seeds={0, 1},\n",
        "    experiment_config=experiment_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        ")\n",
        "benchmark.run_sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up WANDB"
      ],
      "metadata": {
        "id": "Ny9nTZKnun0U"
      },
      "id": "Ny9nTZKnun0U"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "3cY6yxzVunQh",
        "outputId": "a59942ca-c1fb-40af-b329-297714b045cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3cY6yxzVunQh",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "ZvCuWGziuzvt",
        "outputId": "57d61678-d6ff-4c6c-9b31-fe4780f5d8ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZvCuWGziuzvt",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriele-masiero2002\u001b[0m (\u001b[33mgabriele-masiero2002-universit-degli-studi-di-verona\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Via Marl-eval"
      ],
      "metadata": {
        "id": "dn3Dk7ktwrY7"
      },
      "id": "dn3Dk7ktwrY7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install benchmarl matplotlib"
      ],
      "metadata": {
        "id": "JatbsAJkvwq-",
        "outputId": "02b5ada2-e361-4c07-e012-cbbc0ca9f280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JatbsAJkvwq-",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: benchmarl in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: torchrl~=0.6.0 in /usr/local/lib/python3.10/dist-packages (from benchmarl) (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from benchmarl) (4.66.6)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from benchmarl) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl) (3.1.0)\n",
            "Requirement already satisfied: tensordict>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torchrl~=0.6.0->benchmarl) (0.6.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core->benchmarl) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->benchmarl) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->benchmarl) (6.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict>=0.6.0->torchrl~=0.6.0->benchmarl) (3.10.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl~=0.6.0->benchmarl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0->torchrl~=0.6.0->benchmarl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5.0->torchrl~=0.6.0->benchmarl) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "from benchmarl.eval_results import load_and_merge_json_dicts, Plotting\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "Lvt0ItFaFz0f"
      },
      "id": "Lvt0ItFaFz0f",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_benchmark() -> List[str]:\n",
        "    from benchmarl.algorithms import MappoConfig, MasacConfig, MaddpgConfig\n",
        "    from benchmarl.benchmark import Benchmark\n",
        "    from benchmarl.environments import PettingZooTask\n",
        "    from benchmarl.experiment import ExperimentConfig\n",
        "    from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "    # Configure experiment\n",
        "    experiment_config = ExperimentConfig.get_from_yaml()\n",
        "    experiment_config.save_folder = Path(os.getcwd())\n",
        "\n",
        "    experiment_config.loggers = []\n",
        "    experiment_config.max_n_iters = 100\n",
        "\n",
        "    # Configure benchmark\n",
        "    tasks = [PettingZooTask.SIMPLE_ADVERSARY.get_from_yaml(), PettingZooTask.SIMPLE_TAG.get_from_yaml(), PettingZooTask.SIMPLE_SPREAD.get_from_yaml()]\n",
        "    algorithm_configs = [\n",
        "        MappoConfig.get_from_yaml(),\n",
        "        MasacConfig.get_from_yaml(),\n",
        "        MaddpgConfig.get_from_yaml()\n",
        "\n",
        "    ]\n",
        "    model_config = MlpConfig.get_from_yaml()\n",
        "    critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "    benchmark = Benchmark(\n",
        "        algorithm_configs=algorithm_configs,\n",
        "        tasks=tasks,\n",
        "        seeds={0, 1, 27, 42, 95},\n",
        "        experiment_config=experiment_config,\n",
        "        model_config=model_config,\n",
        "        critic_model_config=critic_model_config,\n",
        "    )\n",
        "\n",
        "    # For each experiment, run it and get its output file name\n",
        "    experiments = benchmark.get_experiments()\n",
        "    experiments_json_files = []\n",
        "    for experiment in experiments:\n",
        "        exp_json_file = str(\n",
        "            Path(experiment.folder_name) / Path(experiment.name + \".json\")\n",
        "        )\n",
        "        experiments_json_files.append(exp_json_file)\n",
        "        experiment.run()\n",
        "    return experiments_json_files"
      ],
      "metadata": {
        "id": "h9NTxUp_GFpR"
      },
      "id": "h9NTxUp_GFpR",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the benchmark and process data\n",
        "# Ensure the current working directory is correctly set up\n",
        "current_working_dir = Path(os.getcwd())\n",
        "os.chdir(current_working_dir)\n",
        "\n",
        "# Uncomment to run the benchmark\n",
        "experiments_json_files = run_benchmark()\n",
        "\n",
        "# Load and process experiment outputs\n",
        "raw_dict = load_and_merge_json_dicts(experiments_json_files)\n",
        "processed_data = Plotting.process_data(raw_dict)\n",
        "\n",
        "(\n",
        "    environment_comparison_matrix,\n",
        "    sample_efficiency_matrix,\n",
        ") = Plotting.create_matrices(processed_data, env_name=\"vmas\")\n",
        "\n",
        "# Plotting\n",
        "Plotting.performance_profile_figure(\n",
        "    environment_comparison_matrix=environment_comparison_matrix\n",
        ")\n",
        "Plotting.aggregate_scores(\n",
        "    environment_comparison_matrix=environment_comparison_matrix\n",
        ")\n",
        "Plotting.environemnt_sample_efficiency_curves(\n",
        "    sample_effeciency_matrix=sample_efficiency_matrix\n",
        ")\n",
        "Plotting.task_sample_efficiency_curves(\n",
        "    processed_data=processed_data, env=\"vmas\", task=\"navigation\"\n",
        ")\n",
        "Plotting.probability_of_improvement(\n",
        "    environment_comparison_matrix,\n",
        "    algorithms_to_compare=[[\"qmix\", \"mappo\"]],\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T4VpIPDRIAhk",
        "outputId": "3168f10e-a77e-4a3b-9c14-d97dc9cf8475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "id": "T4VpIPDRIAhk",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9719bee8082b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Uncomment to run the benchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexperiments_json_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load and process experiment outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-295c41c3f3cb>\u001b[0m in \u001b[0;36mrun_benchmark\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Configure experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mexperiment_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperimentConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_from_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mexperiment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mexperiment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mexperiment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_n_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}