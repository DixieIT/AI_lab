{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20326118",
      "metadata": {
        "id": "20326118"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2422f32f",
      "metadata": {
        "id": "2422f32f"
      },
      "source": [
        "## Install BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b10fd32",
      "metadata": {
        "id": "8b10fd32",
        "outputId": "ecfed203-9f2d-4cbc-e424-295eb8ff8bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BenchMARL' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!git clone https://github.com/facebookresearch/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6cd7b69b",
      "metadata": {
        "id": "6cd7b69b",
        "outputId": "17aba316-f32a-467e-d302-2976a60276bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BenchMARL\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd /content/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4f32b88e",
      "metadata": {
        "id": "4f32b88e",
        "outputId": "5b9b0753-8c08-4671-ec60-1ea99df50260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libglu1-mesa\n",
            "Suggested packages:\n",
            "  libgle3 python3-numpy\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libglu1-mesa python3-opengl\n",
            "0 upgraded, 3 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 824 kB of archives.\n",
            "After this operation, 8,092 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n",
            "Fetched 824 kB in 1s (1,084 kB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 126387 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../python3-opengl_3.1.5+dfsg-1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.5+dfsg-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up python3-opengl (3.1.5+dfsg-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.10/dist-packages (1.5.27)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install -U torch torchvision\n",
        "!pip install -e .\n",
        "!apt-get install -y python3-opengl xvfb\n",
        "!pip install pyglet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585d3a35",
      "metadata": {
        "id": "585d3a35"
      },
      "source": [
        "## Install VMAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2e551b1",
      "metadata": {
        "id": "d2e551b1",
        "outputId": "c0695af1-8b1a-4c77-9839-9c75aa6ee4e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vmas\n",
            "  Using cached vmas-1.4.3.tar.gz (211 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from vmas) (2.5.1)\n",
            "Collecting pyglet<=1.5.27 (from vmas)\n",
            "  Using cached pyglet-1.5.27-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from vmas) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->vmas) (3.0.2)\n",
            "Using cached pyglet-1.5.27-py3-none-any.whl (1.1 MB)\n",
            "Building wheels for collected packages: vmas\n",
            "  Building wheel for vmas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vmas: filename=vmas-1.4.3-py3-none-any.whl size=251650 sha256=d78eba5c815fc3f23ad936506357c446a262333331d503bd6840f2cb0c4dd0bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/26/e7/4cea32dc0e5c830808affe26bfd854dc4fd6075939c46ba4f0\n",
            "Successfully built vmas\n",
            "Installing collected packages: pyglet, vmas\n",
            "Successfully installed pyglet-1.5.27 vmas-1.4.3\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install vmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "33d72783",
      "metadata": {
        "id": "33d72783",
        "outputId": "0bf87651-52ef-455b-e54b-354dbc83a399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Connected to r2u.stat.ill\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxkbfile1 libxtst6 libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxkbfile1 libxtst6 libxxf86dga1 x11-utils\n",
            "0 upgraded, 5 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 318 kB of archives.\n",
            "After this operation, 1,053 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Fetched 318 kB in 1s (565 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxfont2 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libxfont2 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 7 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 7,728 kB of archives.\n",
            "After this operation, 11.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 7,728 kB in 1s (8,818 kB/s)\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "(Reading database ... 123692 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../1-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../2-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../3-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../4-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../5-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../6-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick-6-common\n",
            "  imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0 libmagickcore-6.q16-6\n",
            "  libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10 libwmflite-0.2-7 netpbm\n",
            "  poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre ghostscript-x imagemagick-doc\n",
            "  autotrace cups-bsd | lpr | lprng enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer\n",
            "  povray radiance sane-utils texlive-base-bin transfig ufraw-batch libfftw3-bin libfftw3-dev\n",
            "  inkscape poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick\n",
            "  imagemagick-6-common imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0\n",
            "  libmagickcore-6.q16-6 libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10\n",
            "  libwmflite-0.2-7 netpbm poppler-data\n",
            "0 upgraded, 26 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 25.1 MB of archives.\n",
            "After this operation, 87.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu8 [770 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6-common all 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [64.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [1,795 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickwand-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [328 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.9 [752 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.9 [5,033 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.9 [49.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.5 [3,120 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6.q16 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [224 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [14.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre-text all 3.5.28-2build2 [50.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre21 amd64 3.5.28-2build2 [624 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr0 amd64 1.2~git20170615.f752187-5 [174 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr-tools amd64 1.2~git20170615.f752187-5 [16.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwmflite-0.2-7 amd64 0.2.12-5ubuntu1 [68.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6-extra amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [70.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnetpbm10 amd64 2:10.0-15.4 [59.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 netpbm amd64 2:10.0-15.4 [1,007 kB]\n",
            "Fetched 25.1 MB in 1s (19.5 MB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 124245 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../01-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../02-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../03-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../04-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickwand-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../16-imagemagick-6.q16_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../17-imagemagick_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../18-libdjvulibre-text_3.5.28-2build2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../19-libdjvulibre21_3.5.28-2build2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libjxr0:amd64.\n",
            "Preparing to unpack .../20-libjxr0_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libjxr-tools.\n",
            "Preparing to unpack .../21-libjxr-tools_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libwmflite-0.2-7:amd64.\n",
            "Preparing to unpack .../22-libwmflite-0.2-7_0.2.12-5ubuntu1_amd64.deb ...\n",
            "Unpacking libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6-extra:amd64.\n",
            "Preparing to unpack .../23-libmagickcore-6.q16-6-extra_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../24-libnetpbm10_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.4) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../25-netpbm_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.4) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.4) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up netpbm (2:10.0-15.4) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libdjvulibre-text (3.5.28-2build2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7a48e9bd87f0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#@title\n",
        "!apt-get update\n",
        "!apt-get install -y x11-utils\n",
        "!apt-get install -y xvfb\n",
        "!apt-get install -y imagemagick\n",
        "!pip install pyvirtualdisplay\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa7225f",
      "metadata": {
        "id": "caa7225f"
      },
      "source": [
        "# Launch from command line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30075032",
      "metadata": {
        "id": "30075032"
      },
      "source": [
        "To launch an experiment from the command line you can do"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5369898f",
      "metadata": {
        "scrolled": false,
        "id": "5369898f",
        "outputId": "5b36a25f-358f-4b19-c85a-4dfbd25ef008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "Error executing job with overrides: ['algorithm=mappo', 'task=vmas/balance', 'experiment.max_n_iters=2', 'experiment.loggers=[]']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 25, in <module>\n",
            "    from pyglet.gl import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/__init__.py\", line 95, in <module>\n",
            "    from pyglet.gl.gl import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/gl.py\", line 45, in <module>\n",
            "    from pyglet.gl.lib import link_GL as _link_function\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib.py\", line 149, in <module>\n",
            "    from pyglet.gl.lib_glx import link_GL, link_GLU, link_GLX\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib_glx.py\", line 46, in <module>\n",
            "    glu_lib = pyglet.lib.load_library('GLU')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/lib.py\", line 168, in load_library\n",
            "    raise ImportError('Library \"%s\" not found.' % names[0])\n",
            "ImportError: Library \"GLU\" not found.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/BenchMARL/benchmarl/run.py\", line 38, in hydra_experiment\n",
            "    experiment.run()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 571, in run\n",
            "    raise err\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 563, in run\n",
            "    self._collection_loop()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 685, in _collection_loop\n",
            "    self._evaluation_loop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 818, in _evaluation_loop\n",
            "    rollouts = self.test_env.rollout(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2641, in rollout\n",
            "    tensordicts = self._rollout_nonstop(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2814, in _rollout_nonstop\n",
            "    callback(self, tensordict)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 798, in callback\n",
            "    self.task.__class__.render_callback(self, env, td)\n",
            "  File \"/content/BenchMARL/benchmarl/environments/common.py\", line 299, in render_callback\n",
            "    return env.render(mode=\"rgb_array\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 706, in render\n",
            "    self._init_rendering()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 879, in _init_rendering\n",
            "    from vmas.simulator import rendering\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 60, in <module>\n",
            "    raise ImportError(\n",
            "ImportError: Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "mean return = -5.014926910400391:   0% 0/2 [00:31<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py algorithm=mappo task=vmas/balance experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f9338f",
      "metadata": {
        "id": "23f9338f"
      },
      "source": [
        "You can run benchmarks as multi-runs like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "90a135ea",
      "metadata": {
        "scrolled": false,
        "id": "90a135ea",
        "outputId": "ea8a9e6f-c76c-4e7d-ac66-9fb7f72df6be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-10 21:06:20,074][HYDRA] Launching 12 jobs locally\n",
            "[2024-11-10 21:06:20,074][HYDRA] \t#0 : algorithm=mappo task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:06:52,217][HYDRA] \t#1 : algorithm=mappo task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:07:24,506][HYDRA] \t#2 : algorithm=mappo task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:08:15,686][HYDRA] \t#3 : algorithm=mappo task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:09:09,267][HYDRA] \t#4 : algorithm=qmix task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:09:38,251][HYDRA] \t#5 : algorithm=qmix task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:10:09,319][HYDRA] \t#6 : algorithm=qmix task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:10:57,969][HYDRA] \t#7 : algorithm=qmix task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:11:46,362][HYDRA] \t#8 : algorithm=masac task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:12:32,802][HYDRA] \t#9 : algorithm=masac task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:13:19,487][HYDRA] \t#10 : algorithm=masac task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "[2024-11-10 21:14:26,129][HYDRA] \t#11 : algorithm=masac task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  gamma: 0.9\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Experiment failed and is closing gracefully\n",
            "\n",
            "\n",
            "Error executing job with overrides: ['algorithm=mappo', 'task=vmas/balance', 'seed=0', 'experiment.max_n_iters=2', 'experiment.loggers=[]']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 25, in <module>\n",
            "    from pyglet.gl import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/__init__.py\", line 95, in <module>\n",
            "    from pyglet.gl.gl import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/gl.py\", line 45, in <module>\n",
            "    from pyglet.gl.lib import link_GL as _link_function\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib.py\", line 149, in <module>\n",
            "    from pyglet.gl.lib_glx import link_GL, link_GLU, link_GLX\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib_glx.py\", line 46, in <module>\n",
            "    glu_lib = pyglet.lib.load_library('GLU')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyglet/lib.py\", line 168, in load_library\n",
            "    raise ImportError('Library \"%s\" not found.' % names[0])\n",
            "ImportError: Library \"GLU\" not found.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/BenchMARL/benchmarl/run.py\", line 38, in hydra_experiment\n",
            "    experiment.run()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 571, in run\n",
            "    raise err\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 563, in run\n",
            "    self._collection_loop()\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 685, in _collection_loop\n",
            "    self._evaluation_loop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 818, in _evaluation_loop\n",
            "    rollouts = self.test_env.rollout(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2641, in rollout\n",
            "    tensordicts = self._rollout_nonstop(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\", line 2814, in _rollout_nonstop\n",
            "    callback(self, tensordict)\n",
            "  File \"/content/BenchMARL/benchmarl/experiment/experiment.py\", line 798, in callback\n",
            "    self.task.__class__.render_callback(self, env, td)\n",
            "  File \"/content/BenchMARL/benchmarl/environments/common.py\", line 299, in render_callback\n",
            "    return env.render(mode=\"rgb_array\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 706, in render\n",
            "    self._init_rendering()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\", line 879, in _init_rendering\n",
            "    from vmas.simulator import rendering\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\", line 60, in <module>\n",
            "    raise ImportError(\n",
            "ImportError: Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "mean return = -5.014926910400391:   0% 0/2 [09:13<?, ?it/s]\n",
            "mean return = -5.075616359710693:   0% 0/2 [08:40<?, ?it/s]\n",
            "mean return = 3.1488149166107178:   0% 0/2 [08:05<?, ?it/s]\n",
            "mean return = 3.126894950866699:   0% 0/2 [07:13<?, ?it/s]\n",
            "mean return = -10.58658504486084:   0% 0/2 [06:24<?, ?it/s]\n",
            "mean return = -11.010995864868164:   0% 0/2 [05:54<?, ?it/s]\n",
            "mean return = 4.790381908416748:   0% 0/2 [05:20<?, ?it/s]\n",
            "mean return = 3.8009302616119385:   0% 0/2 [04:31<?, ?it/s]\n",
            "mean return = -5.014926910400391:   0% 0/2 [03:46<?, ?it/s]\n",
            "mean return = 3.126894950866699:   0% 0/2 [01:03<?, ?it/s]\n",
            "mean return = -5.075616359710693:   0% 0/2 [03:00<?, ?it/s]\n",
            "mean return = 3.1488149166107178:   0% 0/2 [02:10<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1 experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b01091a",
      "metadata": {
        "id": "0b01091a"
      },
      "source": [
        "# Launch from a python script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c6dc69",
      "metadata": {
        "id": "67c6dc69"
      },
      "source": [
        "You can also load and launch your experiments from within a script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2c5b5fcd",
      "metadata": {
        "id": "2c5b5fcd",
        "outputId": "a041f1b7-02ae-430e-e76f-8ec22f8b16fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "mean return = -5.014926910400391:  50%|     | 1/2 [00:36<00:36, 36.56s/it]\u001b[A\n",
            "mean return = -6.981141090393066: 100%|| 2/2 [01:09<00:00, 34.84s/it]\n"
          ]
        }
      ],
      "source": [
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import PettingZooTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas/balance.yaml\"\n",
        "task = PettingZooTask.SIMPLESPREAD.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/algorithm/mappo.yaml\"\n",
        "algorithm_config = MappoConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/model/layers/mlp.yaml\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "experiment = Experiment(\n",
        "    task=task,\n",
        "    algorithm_config=algorithm_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        "    seed=0,\n",
        "    config=experiment_config,\n",
        ")\n",
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20864e3",
      "metadata": {
        "id": "a20864e3"
      },
      "source": [
        "You can also run multiple experiments in a Benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec3bd4b",
      "metadata": {
        "id": "6ec3bd4b"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig, MasacConfig, QmixConfig\n",
        "from benchmarl.benchmark import Benchmark\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas\"\n",
        "tasks = [VmasTask.BALANCE.get_from_yaml(), VmasTask.SAMPLING.get_from_yaml()]\n",
        "# Loads from \"benchmarl/conf/algorithm\"\n",
        "algorithm_configs = [\n",
        "    MappoConfig.get_from_yaml(),\n",
        "    QmixConfig.get_from_yaml(),\n",
        "    MasacConfig.get_from_yaml(),\n",
        "]\n",
        "# Loads from \"benchmarl/conf/model/layers\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "benchmark = Benchmark(\n",
        "    algorithm_configs=algorithm_configs,\n",
        "    tasks=tasks,\n",
        "    seeds={0, 1},\n",
        "    experiment_config=experiment_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        ")\n",
        "benchmark.run_sequential()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}